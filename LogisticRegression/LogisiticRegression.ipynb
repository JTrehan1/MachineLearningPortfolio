{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logistic Regression</h1>\n",
    "\n",
    "Logistic regression is a supervised machine learning algorithm, that predicts the probability of a datapoint beloning to a certain category. These probabilities are used to assign observations to the more probable group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Linear Regression Approach</h3>\n",
    "\n",
    "The y variable in this case is binary for logistic regression. This does not make sense for logistic regression so apply logit link function to the left hand side of the linear regression model.\n",
    "\n",
    "The equation is:\n",
    "\n",
    "ln(p/1-p) = b_0 +b_1x_1 +b_2x_2...\n",
    "\n",
    "Inside the natural logarithm is the odds. \n",
    "\n",
    "The sigmoid function is the inverse of the logit function and produces a curve of probability for x values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas and the data\n",
    "import pandas as pd\n",
    "codecademyU = pd.read_csv('codecademyU_2.csv')\n",
    "\n",
    "# Separate out X and y\n",
    "X = codecademyU[['hours_studied', 'practice_test']]\n",
    "y = codecademyU.passed_exam\n",
    "\n",
    "# Transform X\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 27)\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "cc_lr = LogisticRegression()\n",
    "cc_lr.fit(X_train,y_train)\n",
    "\n",
    "# Print out the predicted outcomes for the test data\n",
    "print(cc_lr.predict(X_test))\n",
    "\n",
    "# Print out the predicted probabilities for the test data\n",
    "print(cc_lr.predict_proba(X_test)[:,1])\n",
    "# Print out the true outcomes for the test data\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Classification Thresholding</h2>\n",
    "\n",
    "The default threshold in sklearn is 0.5. Dependent on use case the threshold can be changed, for example cancer diagnosis. To ensure most patients with cancer are identified the threshold can be moved down, increasing the positive classification sensitivity. This can sometimes increase this overall number of misclassifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Confusion Matrix</h2>\n",
    "\n",
    "Information about the number of fals positives and negatives:\n",
    "\n",
    "<code>from sklearn import confusion_matrix\n",
    "    confusionMatrix = confusion_matrix(y_true, y_pred)</code>\n",
    "\n",
    "Ouputs an array\n",
    "<code>[[true neg, false pos],\n",
    "        [false neg, true pos]]</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy = (TP + TN)/(TP + FP + TN + FN)\n",
    "\n",
    "Precision = TP/(TP + FP)\n",
    "\n",
    "Recall = TP/(TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy:\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "# output: 0.7\n",
    "\n",
    "# precision:\n",
    "from sklearn.metrics import precision_score\n",
    "print(precision_score(y_true, y_pred))\n",
    "# output: 0.67\n",
    "\n",
    "# recall: \n",
    "from sklearn.metrics import recall_score\n",
    "print(recall_score(y_true, y_pred))\n",
    "# output: 0.8\n",
    "\n",
    "# F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_true, y_pred))\n",
    "# output: 0.73"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
